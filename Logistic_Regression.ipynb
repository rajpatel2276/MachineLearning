{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3486b897-878f-447d-8ed4-05f1fe2b873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbf838ac-fdca-4e91-ab29-726e8c6c7dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a836fcf-0300-4526-a618-f04a8a91075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data_Folder/titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e913a9c6-e3b8-4ca8-8436-d0927143544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb06e99d-23d0-45f0-8597-30dc805753fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='cabin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f04f735b-09a8-4ae0-8037-a091ac2a2c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the numerical gaps\n",
    "median_age = df['age'].median()\n",
    "df['age'] = df['age'].fillna(median_age)\n",
    "# Droping missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0b515cc-9abe-45ef-8ca0-a482836da8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['familysize'] = df['sibsp'] + df['parch']\n",
    "df = df.drop(columns=['sibsp','parch'])\n",
    "\n",
    "# 1.Binary Encoding for the sex column\n",
    "df['sex'] = df['sex'].map({'male':0,'female':1})\n",
    "\n",
    "# 2.One hot encoding for embarked column\n",
    "df = pd.get_dummies(df,columns=['embarked'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2113498e-4bee-4c4f-8b8d-7a5471dc2408",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_scale = ['age','fare','familysize']\n",
    "\n",
    "for col in cols_scale:\n",
    "    min_val = df[col].min()\n",
    "    max_val = df[col].max()\n",
    "    df[col] = (df[col] - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3d0a69d-5a34-4cb2-9bf6-9ef1604fdd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['pclass','sex','age','fare','familysize','embarked_Q','embarked_S']\n",
    "X = df[features].values\n",
    "y = df['survived'].values\n",
    "\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af245b3e-172d-49bb-b864-41c69ec0e92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogisticRegression:\n",
    "    def __init__(self,learning_rate=0.01,iterations=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.cost_history = []\n",
    "    def _sigmoid(self,z):\n",
    "        if not hasattr(np, \"exp\"):\n",
    "            raise TypeError(\"np is not NumPy! Did you overwrite it?\")\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        n_samples,n_features = X.shape\n",
    "        y = y.reshape(-1,1)\n",
    "\n",
    "        self.weights = np.zeros((n_features,1))\n",
    "        self.bias = 0\n",
    "\n",
    "        for i in range(self.iterations):\n",
    "            linear_model = np.dot(X,self.weights) + self.bias\n",
    "\n",
    "            # Applying sigmoid function\n",
    "            y_pred = self._sigmoid(linear_model)\n",
    "\n",
    "            # Cost Calculation (log loss)\n",
    "            epsilon = 1e-15\n",
    "            y_pred_clipped = np.clip(y_pred,epsilon,1-epsilon)\n",
    "            cost = -(1/n_samples) * np.sum(y*np.log(y_pred_clipped)+(1-y) * np.log(1-y_pred_clipped))\n",
    "            self.cost_history.append(cost)\n",
    "\n",
    "            # Backward pass\n",
    "            error = y_pred - y\n",
    "            dw = (1/n_samples) * np.dot(X.T, error)\n",
    "            db = (1/n_samples) * np.sum(error)\n",
    "\n",
    "            # updating the parameters\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Iter {i}: Cost {cost:.4f}\")\n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted = self._sigmoid(linear_model)\n",
    "        # CHANGE 3: Convert Probability to Class (0 or 1)\n",
    "        # If probability > 0.5, class is 1. Else 0.\n",
    "        return [1 if i > 0.5 else 0 for i in y_predicted]            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e226cdc-1425-40e8-b680-01b504a9079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37f6556a-f520-4a10-aeb1-45e7cddb97c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81e7f5fb-f249-468f-ae94-8bbd587a7c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 711 passengers...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training on {len(X_train)} passengers...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4497ded3-cff7-4913-8efc-7f9fea737272",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8411e676-5f54-400c-90eb-d441e17115a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: Cost 0.6931\n",
      "Iter 100: Cost 0.5294\n",
      "Iter 200: Cost 0.4912\n",
      "Iter 300: Cost 0.4762\n",
      "Iter 400: Cost 0.4692\n",
      "Iter 500: Cost 0.4655\n",
      "Iter 600: Cost 0.4632\n",
      "Iter 700: Cost 0.4615\n",
      "Iter 800: Cost 0.4602\n",
      "Iter 900: Cost 0.4591\n",
      "Iter 1000: Cost 0.4582\n",
      "Iter 1100: Cost 0.4573\n",
      "Iter 1200: Cost 0.4565\n",
      "Iter 1300: Cost 0.4557\n",
      "Iter 1400: Cost 0.4550\n",
      "Iter 1500: Cost 0.4543\n",
      "Iter 1600: Cost 0.4536\n",
      "Iter 1700: Cost 0.4530\n",
      "Iter 1800: Cost 0.4524\n",
      "Iter 1900: Cost 0.4519\n",
      "Iter 2000: Cost 0.4514\n",
      "Iter 2100: Cost 0.4508\n",
      "Iter 2200: Cost 0.4504\n",
      "Iter 2300: Cost 0.4499\n",
      "Iter 2400: Cost 0.4495\n",
      "Iter 2500: Cost 0.4491\n",
      "Iter 2600: Cost 0.4487\n",
      "Iter 2700: Cost 0.4483\n",
      "Iter 2800: Cost 0.4479\n",
      "Iter 2900: Cost 0.4476\n",
      "Iter 3000: Cost 0.4472\n",
      "Iter 3100: Cost 0.4469\n",
      "Iter 3200: Cost 0.4466\n",
      "Iter 3300: Cost 0.4463\n",
      "Iter 3400: Cost 0.4461\n",
      "Iter 3500: Cost 0.4458\n",
      "Iter 3600: Cost 0.4456\n",
      "Iter 3700: Cost 0.4453\n",
      "Iter 3800: Cost 0.4451\n",
      "Iter 3900: Cost 0.4449\n",
      "Iter 4000: Cost 0.4447\n",
      "Iter 4100: Cost 0.4445\n",
      "Iter 4200: Cost 0.4443\n",
      "Iter 4300: Cost 0.4441\n",
      "Iter 4400: Cost 0.4439\n",
      "Iter 4500: Cost 0.4437\n",
      "Iter 4600: Cost 0.4436\n",
      "Iter 4700: Cost 0.4434\n",
      "Iter 4800: Cost 0.4433\n",
      "Iter 4900: Cost 0.4431\n"
     ]
    }
   ],
   "source": [
    "model = MyLogisticRegression(learning_rate=0.1,iterations=5000)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83999b1-ec48-47d0-bbf5-418821c25407",
   "metadata": {},
   "source": [
    "Evaluating the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfa6dc2a-1770-4298-affe-2c58125a3a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96a9c1a3-73ee-476b-aa74-ab6954fe6a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on Test Set: 78.65%\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(predictions == y_test.flatten())\n",
    "print(f\"\\nAccuracy on Test Set: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "966a80d4-27fb-4785-9dda-2e58ceec9ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Accuracy: 79.21%\n",
      "SUCCESS: You matched the industry standard.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "sk_model = LogisticRegression()\n",
    "sk_model.fit(X_train, y_train.flatten())\n",
    "sk_acc = sk_model.score(X_test, y_test.flatten())\n",
    "print(f\"Sklearn Accuracy: {sk_acc * 100:.2f}%\")\n",
    "\n",
    "if abs(accuracy - sk_acc) < 0.05:\n",
    "    print(\"SUCCESS: You matched the industry standard.\")\n",
    "else:\n",
    "    print(\"FAIL: Check your learning rate or normalization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8367297f-d9fb-447d-9585-daa9dba432ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.02975306]\n",
      " [ 2.69797789]\n",
      " [-2.13516701]\n",
      " [ 0.54163975]\n",
      " [-1.49096838]\n",
      " [-0.15116228]\n",
      " [-0.52388091]]\n"
     ]
    }
   ],
   "source": [
    "print(model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a97cfe-fb56-48b4-9d19-cb7413377a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
