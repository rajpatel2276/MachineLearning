{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3486b897-878f-447d-8ed4-05f1fe2b873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbf838ac-fdca-4e91-ab29-726e8c6c7dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a836fcf-0300-4526-a618-f04a8a91075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data_Folder/titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e913a9c6-e3b8-4ca8-8436-d0927143544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8ff53a85-cb78-40a3-b254-d2eeb0c37f4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['cabin'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcabin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:5603\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5455\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5456\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5457\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5464\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5465\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5466\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5467\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5468\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5601\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5602\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5603\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5605\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5606\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5607\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5608\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5609\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5610\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5611\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:4810\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4808\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4809\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4810\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4813\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:4852\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4850\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4851\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4852\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4853\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4855\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4856\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7136\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7137\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['cabin'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=['cabin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04f735b-09a8-4ae0-8037-a091ac2a2c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the numerical gaps\n",
    "median_age = df['age'].median()\n",
    "df['age'] = df['age'].fillna(median_age)\n",
    "# Droping missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b515cc-9abe-45ef-8ca0-a482836da8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['familysize'] = df['sibsp'] + df['parch']\n",
    "df = df.drop(columns=['sibsp','parch'])\n",
    "\n",
    "# 1.Binary Encoding for the sex column\n",
    "df['sex'] = df['sex'].map({'male':0,'female':1})\n",
    "\n",
    "# 2.One hot encoding for embarked column\n",
    "df = pd.get_dummies(df,columns=['embarked'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2113498e-4bee-4c4f-8b8d-7a5471dc2408",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_scale = ['age','fare','familysize']\n",
    "\n",
    "for col in cols_scale:\n",
    "    min_val = df[col].min()\n",
    "    max_val = df[col].max()\n",
    "    df[col] = (df[col] - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d0a69d-5a34-4cb2-9bf6-9ef1604fdd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['pclass','sex','age','fare','familysize','embarked_Q','embarked_S']\n",
    "X = df[features].values\n",
    "y = df['survived'].values\n",
    "\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "af245b3e-172d-49bb-b864-41c69ec0e92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogisticRegression:\n",
    "    def __init__(self,learning_rate=0.01,iterations=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.cost_history = []\n",
    "    def _sigmoid(self,z):\n",
    "        if not hasattr(np, \"exp\"):\n",
    "            raise TypeError(\"np is not NumPy! Did you overwrite it?\")\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        n_samples,n_features = X.shape\n",
    "        y = y.reshape(-1,1)\n",
    "\n",
    "        self.weights = np.zeros((n_features,1))\n",
    "        self.bias = 0\n",
    "\n",
    "        for i in range(self.iterations):\n",
    "            linear_model = np.dot(X,self.weights) + self.bias\n",
    "\n",
    "            # Applying sigmoid function\n",
    "            y_pred = self._sigmoid(linear_model)\n",
    "\n",
    "            # Cost Calculation (log loss)\n",
    "            epsilon = 1e-15\n",
    "            y_pred_clipped = np.clip(y_pred,epsilon,1-epsilon)\n",
    "            cost = -(1/n_samples) * np.sum(y*np.log(y_pred_clipped)+(1-y) * np.log(1-y_pred_clipped))\n",
    "            self.cost_history.append(cost)\n",
    "\n",
    "            # Backward pass\n",
    "            error = y_pred - y\n",
    "            dw = (1/n_samples) * np.dot(X.T, error)\n",
    "            db = (1/n_samples) * np.sum(error)\n",
    "\n",
    "            # updating the parameters\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Iter {i}: Cost {cost:.4f}\")\n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted = self._sigmoid(linear_model)\n",
    "        # CHANGE 3: Convert Probability to Class (0 or 1)\n",
    "        # If probability > 0.5, class is 1. Else 0.\n",
    "        return [1 if i > 0.5 else 0 for i in y_predicted]            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "37f6556a-f520-4a10-aeb1-45e7cddb97c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = 700\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "81e7f5fb-f249-468f-ae94-8bbd587a7c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 700 passengers...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training on {len(X_train)} passengers...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4497ded3-cff7-4913-8efc-7f9fea737272",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8411e676-5f54-400c-90eb-d441e17115a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: Cost 0.6931\n",
      "Iter 100: Cost 0.5303\n",
      "Iter 200: Cost 0.4922\n",
      "Iter 300: Cost 0.4778\n",
      "Iter 400: Cost 0.4715\n",
      "Iter 500: Cost 0.4683\n",
      "Iter 600: Cost 0.4665\n",
      "Iter 700: Cost 0.4653\n",
      "Iter 800: Cost 0.4644\n",
      "Iter 900: Cost 0.4637\n",
      "Iter 1000: Cost 0.4631\n",
      "Iter 1100: Cost 0.4625\n",
      "Iter 1200: Cost 0.4620\n",
      "Iter 1300: Cost 0.4615\n",
      "Iter 1400: Cost 0.4611\n",
      "Iter 1500: Cost 0.4607\n",
      "Iter 1600: Cost 0.4603\n",
      "Iter 1700: Cost 0.4599\n",
      "Iter 1800: Cost 0.4595\n",
      "Iter 1900: Cost 0.4591\n",
      "Iter 2000: Cost 0.4588\n",
      "Iter 2100: Cost 0.4585\n",
      "Iter 2200: Cost 0.4582\n",
      "Iter 2300: Cost 0.4579\n",
      "Iter 2400: Cost 0.4576\n",
      "Iter 2500: Cost 0.4573\n",
      "Iter 2600: Cost 0.4571\n",
      "Iter 2700: Cost 0.4568\n",
      "Iter 2800: Cost 0.4566\n",
      "Iter 2900: Cost 0.4564\n",
      "Iter 3000: Cost 0.4561\n",
      "Iter 3100: Cost 0.4559\n",
      "Iter 3200: Cost 0.4557\n",
      "Iter 3300: Cost 0.4555\n",
      "Iter 3400: Cost 0.4554\n",
      "Iter 3500: Cost 0.4552\n",
      "Iter 3600: Cost 0.4550\n",
      "Iter 3700: Cost 0.4549\n",
      "Iter 3800: Cost 0.4547\n",
      "Iter 3900: Cost 0.4546\n",
      "Iter 4000: Cost 0.4544\n",
      "Iter 4100: Cost 0.4543\n",
      "Iter 4200: Cost 0.4542\n",
      "Iter 4300: Cost 0.4540\n",
      "Iter 4400: Cost 0.4539\n",
      "Iter 4500: Cost 0.4538\n",
      "Iter 4600: Cost 0.4537\n",
      "Iter 4700: Cost 0.4536\n",
      "Iter 4800: Cost 0.4535\n",
      "Iter 4900: Cost 0.4534\n"
     ]
    }
   ],
   "source": [
    "model = MyLogisticRegression(learning_rate=0.1,iterations=5000)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83999b1-ec48-47d0-bbf5-418821c25407",
   "metadata": {},
   "source": [
    "Evaluating the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dfa6dc2a-1770-4298-affe-2c58125a3a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96a9c1a3-73ee-476b-aa74-ab6954fe6a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on Test Set: 81.48%\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(predictions == y_test.flatten())\n",
    "print(f\"\\nAccuracy on Test Set: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "966a80d4-27fb-4785-9dda-2e58ceec9ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Accuracy: 81.48%\n",
      "SUCCESS: You matched the industry standard.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "sk_model = LogisticRegression()\n",
    "sk_model.fit(X_train, y_train.flatten())\n",
    "sk_acc = sk_model.score(X_test, y_test.flatten())\n",
    "print(f\"Sklearn Accuracy: {sk_acc * 100:.2f}%\")\n",
    "\n",
    "if abs(accuracy - sk_acc) < 0.05:\n",
    "    print(\"SUCCESS: You matched the industry standard.\")\n",
    "else:\n",
    "    print(\"FAIL: Check your learning rate or normalization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8367297f-d9fb-447d-9585-daa9dba432ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.97441115]\n",
      " [ 2.6656903 ]\n",
      " [-1.69630815]\n",
      " [ 0.31456144]\n",
      " [-1.36099906]\n",
      " [ 0.07729933]\n",
      " [-0.33749188]]\n"
     ]
    }
   ],
   "source": [
    "print(model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a97cfe-fb56-48b4-9d19-cb7413377a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
