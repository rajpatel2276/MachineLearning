{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68b6e397-e973-49dc-bed8-fe884bdfc82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b872bd9b-8519-44dd-ba54-51a51339a133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_Derivative(func,x,h=1e-5):\n",
    "    fx_plus = func(x+h)\n",
    "    fx = func(x)\n",
    "\n",
    "    slope = (fx_plus - fx)/h\n",
    "    return slope\n",
    "\n",
    "    # testing on real function\n",
    "def my_square(x):\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7782187-057b-43e5-b53f-5c1ff64462a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope at x=3: 6.00001\n"
     ]
    }
   ],
   "source": [
    "slope_at_3 = numerical_Derivative(my_square, 3)\n",
    "print(f\"Slope at x=3: {slope_at_3:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8f05c9-e7c5-49dd-9ae9-40c06dd4e3ed",
   "metadata": {},
   "source": [
    "More generalised numerical derivative function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21d02965-83a1-40f8-b7c4-c2bece3c938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative_general(func,x,h=1e-5,order=1,method=\"central\"):\n",
    "    if isinstance(x,(int,float)):\n",
    "        if(order == 1):\n",
    "            if(method==\"forward\"):\n",
    "                return (func(x+h)-func(x)) / h\n",
    "            elif(method==\"backward\"):\n",
    "                return (func(x)-func(x-h)) / h\n",
    "            elif(method==\"central\"):\n",
    "                return (func(x+h)-func(x-h)) / (2*h)\n",
    "\n",
    "        elif order == 2:\n",
    "            return (func(x + h) - 2*func(x) + func(x - h)) / (h**2)\n",
    "    elif isinstance(x,(list,tuple)):\n",
    "        x = list(x)\n",
    "        grad = []\n",
    "        for i in range(len(x)):\n",
    "            x_forward = x.copy()\n",
    "            x_backward = x.copy()\n",
    "            x_forward[i] += h\n",
    "            x_backward[i] -= h\n",
    "\n",
    "            dfi = (func(x_forward) - func(x_backward)) / (2*h)\n",
    "            grad.append(dfi)\n",
    "        return grad\n",
    "    else:\n",
    "        raise TypeError(\"x must be float , int , list or tuple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "022fdb5e-7b2c-4b7f-90e6-7974f62350b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.000000000039306\n"
     ]
    }
   ],
   "source": [
    "def f(x): return x**2\n",
    "print(numerical_derivative_general(f, 3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1e5a97b-2693-4c7a-a3c6-c8c406baa341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9999824019123478\n"
     ]
    }
   ],
   "source": [
    "def f(x): return x**2\n",
    "print(numerical_derivative_general(f, 3, order=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f38e0871-ed61-4192-8a98-8dd879238bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(start_w,learning_rate,steps):\n",
    "    w = start_w\n",
    "    history = []\n",
    "\n",
    "    def cost_func(val):\n",
    "        return (val-5)**2\n",
    "    print(f\"starting at w = {w}\")\n",
    "\n",
    "    for i in range(steps):\n",
    "        gradient = numerical_derivative_general(cost_func,w)\n",
    "\n",
    "        w = w - (learning_rate*gradient)\n",
    "\n",
    "        history.append(w)\n",
    "        print(f\"Step {i+1}: w = {w:.4f}, Gradient = {gradient:.4f}, Cost = {cost_func(w):.4f}\")\n",
    "    return w,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcdb1d94-41de-4e66-a766-2d78a689a395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting at w = 0.0\n",
      "Step 1: w = 1.0000, Gradient = -10.0000, Cost = 16.0000\n",
      "Step 2: w = 1.8000, Gradient = -8.0000, Cost = 10.2400\n",
      "Step 3: w = 2.4400, Gradient = -6.4000, Cost = 6.5536\n",
      "Step 4: w = 2.9520, Gradient = -5.1200, Cost = 4.1943\n",
      "Step 5: w = 3.3616, Gradient = -4.0960, Cost = 2.6844\n",
      "Step 6: w = 3.6893, Gradient = -3.2768, Cost = 1.7180\n",
      "Step 7: w = 3.9514, Gradient = -2.6214, Cost = 1.0995\n",
      "Step 8: w = 4.1611, Gradient = -2.0972, Cost = 0.7037\n",
      "Step 9: w = 4.3289, Gradient = -1.6777, Cost = 0.4504\n",
      "Step 10: w = 4.4631, Gradient = -1.3422, Cost = 0.2882\n",
      "Step 11: w = 4.5705, Gradient = -1.0737, Cost = 0.1845\n",
      "Step 12: w = 4.6564, Gradient = -0.8590, Cost = 0.1181\n",
      "Step 13: w = 4.7251, Gradient = -0.6872, Cost = 0.0756\n",
      "Step 14: w = 4.7801, Gradient = -0.5498, Cost = 0.0484\n",
      "Step 15: w = 4.8241, Gradient = -0.4398, Cost = 0.0309\n",
      "Step 16: w = 4.8593, Gradient = -0.3518, Cost = 0.0198\n",
      "Step 17: w = 4.8874, Gradient = -0.2815, Cost = 0.0127\n",
      "Step 18: w = 4.9099, Gradient = -0.2252, Cost = 0.0081\n",
      "Step 19: w = 4.9279, Gradient = -0.1801, Cost = 0.0052\n",
      "Step 20: w = 4.9424, Gradient = -0.1441, Cost = 0.0033\n",
      "Step 21: w = 4.9539, Gradient = -0.1153, Cost = 0.0021\n",
      "Step 22: w = 4.9631, Gradient = -0.0922, Cost = 0.0014\n",
      "Step 23: w = 4.9705, Gradient = -0.0738, Cost = 0.0009\n",
      "Step 24: w = 4.9764, Gradient = -0.0590, Cost = 0.0006\n",
      "Step 25: w = 4.9811, Gradient = -0.0472, Cost = 0.0004\n",
      "Step 26: w = 4.9849, Gradient = -0.0378, Cost = 0.0002\n",
      "Step 27: w = 4.9879, Gradient = -0.0302, Cost = 0.0001\n",
      "Step 28: w = 4.9903, Gradient = -0.0242, Cost = 0.0001\n",
      "Step 29: w = 4.9923, Gradient = -0.0193, Cost = 0.0001\n",
      "Step 30: w = 4.9938, Gradient = -0.0155, Cost = 0.0000\n"
     ]
    }
   ],
   "source": [
    "final_w = gradient_descent(0.0,0.1,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24521006-4eef-4b78-81b9-5d6b0e8d1f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_2d(learning_rate,steps):\n",
    "    x = 10\n",
    "    y = -10\n",
    "\n",
    "    def cost_func_2d(x_val,y_val):\n",
    "        return x_val**2 + y_val**2\n",
    "    history = []\n",
    "    for i in range(steps):\n",
    "        def wrapped_func(vec):\n",
    "            return cost_func_2d(vec[0], vec[1])\n",
    "        \n",
    "        grad = numerical_derivative_general(wrapped_func,[x,y])\n",
    "\n",
    "        x = x - learning_rate*grad[0]\n",
    "        y = y - learning_rate*grad[1]\n",
    "\n",
    "        history.append((x, y)) \n",
    "        print(f\"Step {i+1}: x = {x:.4f}, y = {y:.4f}, Gradient = {grad}, Cost = {cost_func_2d(x,y):.4f}\")\n",
    "\n",
    "    return (x,y),history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "100d82d8-4433-4982-9123-673c2ac315fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: x = 8.0000, y = -8.0000, Gradient = [19.999999999242846, -19.999999999242846], Cost = 128.0000\n",
      "Step 2: x = 6.4000, y = -6.4000, Gradient = [15.999999998683732, -15.999999998683732], Cost = 81.9200\n",
      "Step 3: x = 5.1200, y = -5.1200, Gradient = [12.799999999657528, -12.799999999657528], Cost = 52.4288\n",
      "Step 4: x = 4.0960, y = -4.0960, Gradient = [10.240000000294458, -10.240000000294458], Cost = 33.5544\n",
      "Step 5: x = 3.2768, y = -3.2768, Gradient = [8.19199999995135, -8.19199999995135], Cost = 21.4748\n",
      "Step 6: x = 2.6214, y = -2.6214, Gradient = [6.5536000004584585, -6.5536000004584585], Cost = 13.7439\n",
      "Step 7: x = 2.0972, y = -2.0972, Gradient = [5.2428800003667675, -5.2428800003667675], Cost = 8.7961\n",
      "Step 8: x = 1.6777, y = -1.6777, Gradient = [4.194304000293414, -4.194304000293414], Cost = 5.6295\n",
      "Step 9: x = 1.3422, y = -1.3422, Gradient = [3.355443200225849, -3.355443200225849], Cost = 3.6029\n",
      "Step 10: x = 1.0737, y = -1.0737, Gradient = [2.6843545601895613, -2.6843545601895613], Cost = 2.3058\n",
      "Step 11: x = 0.8590, y = -0.8590, Gradient = [2.147483648151649, -2.147483648151649], Cost = 1.4757\n",
      "Step 12: x = 0.6872, y = -0.6872, Gradient = [1.7179869184924532, -1.7179869184924532], Cost = 0.9445\n",
      "Step 13: x = 0.5498, y = -0.5498, Gradient = [1.374389534791742, -1.374389534791742], Cost = 0.6045\n",
      "Step 14: x = 0.4398, y = -0.4398, Gradient = [1.0995116278333938, -1.0995116278333938], Cost = 0.3869\n",
      "Step 15: x = 0.3518, y = -0.3518, Gradient = [0.8796093022761519, -0.8796093022761519], Cost = 0.2476\n",
      "Step 16: x = 0.2815, y = -0.2815, Gradient = [0.7036874418192561, -0.7036874418192561], Cost = 0.1585\n",
      "Step 17: x = 0.2252, y = -0.2252, Gradient = [0.5629499534559601, -0.5629499534559601], Cost = 0.1014\n",
      "Step 18: x = 0.1801, y = -0.1801, Gradient = [0.45035996276351903, -0.45035996276351903], Cost = 0.0649\n",
      "Step 19: x = 0.1441, y = -0.1441, Gradient = [0.3602879702108152, -0.3602879702108152], Cost = 0.0415\n",
      "Step 20: x = 0.1153, y = -0.1153, Gradient = [0.28823037616851344, -0.28823037616851344], Cost = 0.0266\n",
      "Step 21: x = 0.0922, y = -0.0922, Gradient = [0.2305843009343944, -0.2305843009343944], Cost = 0.0170\n",
      "Step 22: x = 0.0738, y = -0.0738, Gradient = [0.1844674407475155, -0.1844674407475155], Cost = 0.0109\n",
      "Step 23: x = 0.0590, y = -0.0590, Gradient = [0.14757395259802977, -0.14757395259802977], Cost = 0.0070\n",
      "Step 24: x = 0.0472, y = -0.0472, Gradient = [0.11805916207857126, -0.11805916207857126], Cost = 0.0045\n",
      "Step 25: x = 0.0378, y = -0.0378, Gradient = [0.09444732966281363, -0.09444732966281363], Cost = 0.0029\n",
      "Step 26: x = 0.0302, y = -0.0302, Gradient = [0.07555786373028561, -0.07555786373028561], Cost = 0.0018\n",
      "Step 27: x = 0.0242, y = -0.0242, Gradient = [0.06044629098419379, -0.06044629098419379], Cost = 0.0012\n",
      "Step 28: x = 0.0193, y = -0.0193, Gradient = [0.048357032787359366, -0.048357032787359366], Cost = 0.0007\n",
      "Step 29: x = 0.0155, y = -0.0155, Gradient = [0.03868562622988099, -0.03868562622988099], Cost = 0.0005\n",
      "Step 30: x = 0.0124, y = -0.0124, Gradient = [0.030948500983908046, -0.030948500983908046], Cost = 0.0003\n",
      "Step 31: x = 0.0099, y = -0.0099, Gradient = [0.02475880078712481, -0.02475880078712481], Cost = 0.0002\n",
      "Step 32: x = 0.0079, y = -0.0079, Gradient = [0.019807040629699034, -0.019807040629699034], Cost = 0.0001\n",
      "Step 33: x = 0.0063, y = -0.0063, Gradient = [0.015845632503760584, -0.015845632503760584], Cost = 0.0001\n",
      "Step 34: x = 0.0051, y = -0.0051, Gradient = [0.012676506003007654, -0.012676506003007654], Cost = 0.0001\n",
      "Step 35: x = 0.0041, y = -0.0041, Gradient = [0.010141204802406259, -0.010141204802406259], Cost = 0.0000\n",
      "Step 36: x = 0.0032, y = -0.0032, Gradient = [0.008112963841925006, -0.008112963841925006], Cost = 0.0000\n",
      "Step 37: x = 0.0026, y = -0.0026, Gradient = [0.006490371073540344, -0.006490371073540344], Cost = 0.0000\n",
      "Step 38: x = 0.0021, y = -0.0021, Gradient = [0.005192296858832258, -0.005192296858832258], Cost = 0.0000\n",
      "Step 39: x = 0.0017, y = -0.0017, Gradient = [0.00415383748706584, -0.00415383748706584], Cost = 0.0000\n",
      "Step 40: x = 0.0013, y = -0.0013, Gradient = [0.003323069989652596, -0.003323069989652596], Cost = 0.0000\n",
      "Step 41: x = 0.0011, y = -0.0011, Gradient = [0.0026584559917220726, -0.0026584559917220726], Cost = 0.0000\n",
      "Step 42: x = 0.0009, y = -0.0009, Gradient = [0.002126764793377671, -0.002126764793377671], Cost = 0.0000\n",
      "Step 43: x = 0.0007, y = -0.0007, Gradient = [0.0017014118347021218, -0.0017014118347021218], Cost = 0.0000\n",
      "Step 44: x = 0.0005, y = -0.0005, Gradient = [0.0013611294677616996, -0.0013611294677616996], Cost = 0.0000\n",
      "Step 45: x = 0.0004, y = -0.0004, Gradient = [0.0010889035742093513, -0.0010889035742093513], Cost = 0.0000\n",
      "Step 46: x = 0.0003, y = -0.0003, Gradient = [0.0008711228593674789, -0.0008711228593674789], Cost = 0.0000\n",
      "Step 47: x = 0.0003, y = -0.0003, Gradient = [0.0006968982874939852, -0.0006968982874939852], Cost = 0.0000\n",
      "Step 48: x = 0.0002, y = -0.0002, Gradient = [0.0005575186299951871, -0.0005575186299951871], Cost = 0.0000\n",
      "Step 49: x = 0.0002, y = -0.0002, Gradient = [0.00044601490399614785, -0.00044601490399614785], Cost = 0.0000\n",
      "Step 50: x = 0.0001, y = -0.0001, Gradient = [0.00035681192319691877, -0.00035681192319691877], Cost = 0.0000\n",
      "((0.00014272476927876753, -0.00014272476927876753), [(8.000000000075715, -8.000000000075715), (6.400000000207342, -6.400000000207342), (5.120000000241589, -5.120000000241589), (4.096000000212143, -4.096000000212143), (3.2768000002170083, -3.2768000002170083), (2.6214400001711624, -2.6214400001711624), (2.0971520001344857, -2.0971520001344857), (1.6777216001051443, -1.6777216001051443), (1.3421772800825593, -1.3421772800825593), (1.0737418240636032, -1.0737418240636032), (0.8589934592484383, -0.8589934592484383), (0.6871947673991929, -0.6871947673991929), (0.5497558139200187, -0.5497558139200187), (0.4398046511366793, -0.4398046511366793), (0.35184372090906413, -0.35184372090906413), (0.2814749767271385, -0.2814749767271385), (0.2251799813815425, -0.2251799813815425), (0.18014398510519058, -0.18014398510519058), (0.14411518808410906, -0.14411518808410906), (0.11529215046725771, -0.11529215046725771), (0.09223372037381827, -0.09223372037381827), (0.07378697629906672, -0.07378697629906672), (0.05902958103926374, -0.05902958103926374), (0.047223664831406616, -0.047223664831406616), (0.03777893186512525, -0.03777893186512525), (0.03022314549209669, -0.03022314549209669), (0.02417851639367731, -0.02417851639367731), (0.019342813114941373, -0.019342813114941373), (0.015474250491953273, -0.015474250491953273), (0.01237940039356247, -0.01237940039356247), (0.009903520314849989, -0.009903520314849989), (0.007922816251880085, -0.007922816251880085), (0.006338253001504027, -0.006338253001504027), (0.005070602401203262, -0.005070602401203262), (0.004056481920962636, -0.004056481920962636), (0.003245185536770135, -0.003245185536770135), (0.0025961484294161007, -0.0025961484294161007), (0.0020769187435328747, -0.0020769187435328747), (0.0016615349948262907, -0.0016615349948262907), (0.001329227995861031, -0.001329227995861031), (0.0010633823966888238, -0.0010633823966888238), (0.0008507059173510567, -0.0008507059173510567), (0.0006805647338808445, -0.0006805647338808445), (0.0005444517871046745, -0.0005444517871046745), (0.0004355614296837393, -0.0004355614296837393), (0.00034844914374699144, -0.00034844914374699144), (0.0002787593149975929, -0.0002787593149975929), (0.0002230074519980742, -0.0002230074519980742), (0.0001784059615984594, -0.0001784059615984594), (0.00014272476927876753, -0.00014272476927876753)])\n"
     ]
    }
   ],
   "source": [
    "print(gradient_descent_2d(0.1,50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29be6714-db75-4581-aa5d-3e09bc0e01e2",
   "metadata": {},
   "source": [
    "back propagation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087264d0-a5cd-4c66-9360-15a8a977f2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHAIN RULE EXERCISE\n",
    "# Scenario:\n",
    "# x (Input) = 2\n",
    "# y = x * 3  (Slope dy/dx = 3)\n",
    "# z = y ** 2 (Slope dz/dy = 2y)\n",
    "\n",
    "# We want dz/dx.\n",
    "# 1. Forward Pass:\n",
    "#    x = 2\n",
    "#    y = 6 (2*3)\n",
    "#    z = 36 (6^2)\n",
    "\n",
    "# 2. Backward Pass:\n",
    "#    Slope dz/dy = 2 * y = 2 * 6 = 12\n",
    "#    Slope dy/dx = 3\n",
    "#    Slope dz/dx = dz/dy * dy/dx = 12 * 3 = 36\n",
    "\n",
    "# VERIFICATION (Numerical):\n",
    "# If I move x from 2.0 to 2.001 (change of 0.001)\n",
    "# z moves from 36.0 to ...?\n",
    "# (2.001 * 3)^2 = 6.003^2 â‰ˆ 36.036\n",
    "# Change in z = 0.036\n",
    "# Slope = 0.036 / 0.001 = 36. MATCH!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
